{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration\n",
    "\n",
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "# from peft import PeftModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input / Memory Extraction 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_tokenizer = AutoTokenizer.from_pretrained(\"prakharz/DIAL-BART0\")\n",
    "inst_model = AutoModelForSeq2SeqLM.from_pretrained(\"prakharz/DIAL-BART0\")\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "sent_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "sent_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "config = AutoConfig.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I like country music.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruct_input = \"Instruction:What is the topic of conversation?\\n\\nInput:[CONTEXT]{}[ENDOFDIALOGUE][QUESTION]The topic of conversation is\".format(user_input)\n",
    "tokens_input = inst_tokenizer(instruct_input, max_length=250, padding='max_length', truncation=True, return_tensors='pt')\n",
    "input_out = inst_model.generate(**tokens_input)\n",
    "topic = inst_tokenizer.decode(input_out[0], skip_special_tokens=True)\n",
    "print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input = sent_tokenizer(user_input, max_length=250, padding='max_length', truncation=True, return_tensors='pt')\n",
    "input_out = sent_model(**tokens_input)\n",
    "\n",
    "scores = softmax(input_out[0][0].detach().numpy())\n",
    "print(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = config.id2label[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic_sentiment(text_in):\n",
    "    instruct_input = \"Instruction:What is the topic of conversation?\\n\\nInput:[CONTEXT]{}[ENDOFDIALOGUE][QUESTION]The topic of conversation is\".format(text_in)\n",
    "    tokens_input = inst_tokenizer(instruct_input, max_length=250, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    input_out = inst_model.generate(**tokens_input)\n",
    "    topic = inst_tokenizer.decode(input_out[0], skip_special_tokens=True)\n",
    "\n",
    "    tokens_input = sent_tokenizer(text_in, max_length=250, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    input_out = sent_model(**tokens_input)\n",
    "\n",
    "    scores = softmax(input_out[0][0].detach().numpy())\n",
    "    #print(scores)\n",
    "\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = config.id2label[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "\n",
    "    return topic, config.id2label[ranking[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS JUST USED FOR DATASET MANIPULATION\n",
    "# file = open('./CoT/generated_ds.csv', 'r')\n",
    "# f2 = open('./CoT/ds.txt', 'w')\n",
    "# lines = file.readlines()\n",
    "\n",
    "# for line in lines:\n",
    "#     idx = line.find(':')\n",
    "#     l2 = '[' + line[:idx]  + ']|' + line[idx+1:]\n",
    "#     f2.write(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI TOPIC GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_tokenizer2 = AutoTokenizer.from_pretrained(\"prakharz/DIAL-BART0\")\n",
    "inst_model2 = AutoModelForSeq2SeqLM.from_pretrained(\"prakharz/DIAL-BART0\")\n",
    "\n",
    "inst_model2.load_state_dict(torch.load('./model/topic_er.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain of topics\n",
    "def generate_cot(text_in):\n",
    "    tok_text = inst_tokenizer2(text_in, return_tensors='pt')\n",
    "    gen_text = inst_model2.generate(**tok_text)\n",
    "    dec_text = inst_tokenizer2.decode(gen_text[0], skip_special_tokens=True)\n",
    "    return dec_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_topic_sentiment(\"I like Abraham Lincoln\"))\n",
    "print(generate_cot(\"Abraham Lincoln\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# META-TOPIC : {Music, Sports, Games}\n",
    "# SUB-TOPIC : {Rock n Roll, Country, etc.}\n",
    "# MICRO-TOPIC : {Journey, Boston, ACDC, Aerosmith}\n",
    "memory = {}\n",
    "\n",
    "def add_to_memory(mem, memory, idx, key=None, value=None):\n",
    "    # print(mem)\n",
    "    if len(mem) == 0:\n",
    "        #print(memory.keys())\n",
    "        if key != None:\n",
    "            if key in memory.keys():\n",
    "                memory[key] = value\n",
    "            else:\n",
    "                memory[key] = value\n",
    "\n",
    "        return memory\n",
    "    \n",
    "    if mem[0] not in memory.keys():\n",
    "        memory[mem[0]] = {}\n",
    "        \n",
    "        if key != None:\n",
    "            #print(mem[0])\n",
    "            #print(memory[mem[0]].keys())\n",
    "            if key not in memory[mem[0]].keys():\n",
    "                memory[mem[0]] = {key:value}\n",
    "\n",
    "    add_to_memory(mem[1:], memory[mem[0]], idx+1, key, value)\n",
    "    return memory\n",
    "\n",
    "print(add_to_memory(['Animals', 'Marine Life', 'Sharks', 'Beach'], memory, 0))\n",
    "print(add_to_memory(['Animals', 'Marine Life', 'Sharks', 'Sand'], memory, 0, 'relationship', 'dislike'))\n",
    "print()\n",
    "print(add_to_memory(['Animals', 'Marine Life', 'Sharks', 'Sand'], memory, 0, 'relationship', 'like'))\n",
    "print(add_to_memory(['Animals', 'Marine Life', 'Sharks', 'Sand'], memory, 0, 'strength', 5))\n",
    "\n",
    "# print(memory['Animals']['Marine Life']['Sharks']['Sand'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Retreive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_memory(mem, memory, idx):\n",
    "    if len(mem) == 0:\n",
    "        return memory\n",
    "    return read_memory(mem[1:], memory[mem[0]], idx+1)\n",
    "\n",
    "print(read_memory(['Animals', 'Marine Life', 'Sharks'], memory, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node2Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(read_memory(['Animals', 'Marine Life', 'Sharks'], memory, 0))+\" <- IS A STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guideline Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Extraction 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE METHOD FROM MEMORY EXTRACTION 1\n",
    "ext = extract_topic_sentiment(\"I do not like reading non-fiction books.\")\n",
    "# WILL NEED TO RUN THIS SENTENCE BY SENTENCE?\n",
    "print(ext)\n",
    "\n",
    "cot = generate_cot(ext[0])\n",
    "print(cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hokieguideliner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
