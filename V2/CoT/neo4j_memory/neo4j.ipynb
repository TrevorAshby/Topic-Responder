{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# https://neo4j.com/docs/cypher-manual/current/introduction/\n",
    "# show everything: MATCH (n) OPTIONAL MATCH (n)-[r]-() RETURN n, r;\n",
    "# delete everything: MATCH (n) DETACH DELETE n\n",
    "\n",
    "# https://workspace-preview.neo4j.io/workspace/query\n",
    "import neo4j_helper\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoConfig,\\\n",
    "      T5ForConditionalGeneration, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dao = neo4j_helper.Neo4jDAO(uri=\"neo4j+s://467d365d.databases.neo4j.io:7687\", user=\"neo4j\", pwd=\"Ssh4fzvQ2dzrSxY0Ru8Vl92SZAQlXuKoZpdmucF0sdM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dao.query('CREATE (n:Person {name: \\'Andy\\', title: \\'Developer\\'})')\n",
    "dao.query('CREATE (n:Person {name: \\'Paul\\', title: \\'Developer\\'})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dao.createEdge2(src_name='Paul', src_type='Person', trg_name='Andy', trg_type='Person', rel_type='friends', two_way=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {\n",
    "    'hi': 'hello',\n",
    "    'imgood': 'are you?'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dao.createNode2('Computer', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# download the models\n",
    "cot_tokenizer = AutoTokenizer.from_pretrained(\"prakharz/DIAL-BART0\")\n",
    "cot_model = AutoModelForSeq2SeqLM.from_pretrained(\"prakharz/DIAL-BART0\")\n",
    "cot_model.load_state_dict(torch.load('../../model/topic_er.pt'))\n",
    "\n",
    "sent_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "sent_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "config = AutoConfig.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "inst_tokenizer = AutoTokenizer.from_pretrained(\"prakharz/DIAL-BART0\")\n",
    "inst_model = AutoModelForSeq2SeqLM.from_pretrained(\"prakharz/DIAL-BART0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic_sentiment(text_in):\n",
    "    instruct_input = \"Instruction:What is the topic of conversation?\\n\\nInput:[CONTEXT]{}[ENDOFDIALOGUE][QUESTION]The topic of conversation is\".format(text_in)\n",
    "    tokens_input = inst_tokenizer(instruct_input, max_length=250, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    input_out = inst_model.generate(**tokens_input)\n",
    "    topic = inst_tokenizer.decode(input_out[0], skip_special_tokens=True)\n",
    "\n",
    "    tokens_input = sent_tokenizer(text_in, max_length=250, padding='max_length', truncation=True, return_tensors='pt')\n",
    "    input_out = sent_model(**tokens_input)\n",
    "\n",
    "    scores = softmax(input_out[0][0].detach().numpy())\n",
    "    #print(scores)\n",
    "\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = config.id2label[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "\n",
    "    return topic, config.id2label[ranking[0]]\n",
    "\n",
    "# chain of topics\n",
    "def generate_cot(text_in):\n",
    "    tok_text = cot_tokenizer(text_in, return_tensors='pt')\n",
    "    gen_text = cot_model.generate(**tok_text)\n",
    "    dec_text = cot_tokenizer.decode(gen_text[0], skip_special_tokens=True)\n",
    "    return dec_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trevi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) positive 0.9812\n",
      "2) neutral 0.0167\n",
      "3) negative 0.0021\n",
      "['Sports', 'Football', 'NCAAAllTimeLeadingScorers'] -> Hokiefootball\n",
      "positive\n",
      "['Sports', 'Football', 'NCAAAllTimeLeadingScorers', 'Hokiefootball']\n"
     ]
    }
   ],
   "source": [
    "in_str = \"I had fun watching the hokie football game.\"\n",
    "\n",
    "topic, sent = extract_topic_sentiment(in_str)\n",
    "dec_out = generate_cot(topic)\n",
    "\n",
    "dec_out = dec_out.replace(' ', '')\n",
    "dec_out = dec_out.replace('-', '')\n",
    "dec_out = dec_out.replace(',', ',')\n",
    "dec_out = dec_out.replace('[', '')\n",
    "dec_out = dec_out.replace(']', '')\n",
    "topic = topic.replace(' ', '')\n",
    "print(\"{} -> {}\".format((dec_out.split(',')), topic))\n",
    "print(sent)\n",
    "\n",
    "cot = dec_out.split(',')\n",
    "cot.append(topic)\n",
    "\n",
    "print(cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"high-level\": {\"topic\": \"weekend\", \"if_interest\": \"yes\"}}\n"
     ]
    }
   ],
   "source": [
    "topic_tokenizer = AutoTokenizer.from_pretrained('prakharz/DIAL-BART0')\n",
    "topic_detector = AutoModelForSeq2SeqLM.from_pretrained('TrevorAshby/topic-detector')\n",
    "\n",
    "user_response = 'I am really happy that I don\\'t have to do any homework this weekend.'\n",
    "\n",
    "topic_in_str = \"Instruction: Extract the topic of the last conversation turn, and determine whether the human is interested in it.\\n Input: [CONTEXT] \" + 'Human: ' + user_response + \" [ENDOFDIALOGUE] [QUESTION] Given this conversation provided, the topic and intent is\"\n",
    "user_input_ids = topic_tokenizer(topic_in_str, max_length=250, padding='max_length', return_tensors='pt').input_ids\n",
    "topic_pref_example = topic_detector.generate(user_input_ids, max_new_tokens=128)\n",
    "topic_pref = topic_tokenizer.decode(topic_pref_example[0], skip_special_tokens=True)\n",
    "print(topic_pref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "preference\n",
      "name\n",
      "preference\n",
      "name\n",
      "preference\n",
      "name\n",
      "preference\n"
     ]
    }
   ],
   "source": [
    "# if positive, mark all as positive\n",
    "if sent == 'positive':\n",
    "    for top in cot:\n",
    "        dao.createNode2(top, {'name':top, 'preference':sent})\n",
    "# if negative/neutral, mark all as unkown except current topic node, mark as neg/neu\n",
    "else:\n",
    "    for idx, top in enumerate(cot):\n",
    "        if idx != len(cot)-1:\n",
    "            dao.createNode2(top, {'name':top, 'preference':'unknown'})\n",
    "        else:\n",
    "            dao.createNode2(top, {'name':top, 'preference':sent})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports Sports\n",
      "Sports Football\n",
      "here\n",
      "Sports NCAAAllTimeLeadingScorers\n",
      "here\n",
      "Sports Hokiefootball\n",
      "here\n",
      "Football Sports\n",
      "here\n",
      "Football Football\n",
      "Football NCAAAllTimeLeadingScorers\n",
      "here\n",
      "Football Hokiefootball\n",
      "here\n",
      "NCAAAllTimeLeadingScorers Sports\n",
      "here\n",
      "NCAAAllTimeLeadingScorers Football\n",
      "here\n",
      "NCAAAllTimeLeadingScorers NCAAAllTimeLeadingScorers\n",
      "NCAAAllTimeLeadingScorers Hokiefootball\n",
      "here\n",
      "Hokiefootball Sports\n",
      "here\n",
      "Hokiefootball Football\n",
      "here\n",
      "Hokiefootball NCAAAllTimeLeadingScorers\n",
      "here\n",
      "Hokiefootball Hokiefootball\n"
     ]
    }
   ],
   "source": [
    "# create all edges\n",
    "for top in cot:\n",
    "    for top2 in cot:\n",
    "        print(top, top2)\n",
    "        if top != top2:\n",
    "            print('here')\n",
    "            dao.createEdge2(src_name=top, src_type=top, trg_name=top2,\\\n",
    "                 trg_type=top2, rel_type='related', two_way=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
